# アルゴリズム仕様書

---

## 1. 名称
**不予測度（Unpredictability）指標を用いたマルチピッチ・ノート検出アルゴリズム**

---

## 2. 技術分野
本発明は、音楽音響信号処理、特に楽音に含まれる複数の音高成分（マルチピッチ）と、その始まりおよび終わりを検出するノートセグメンテーション技術に関する。音声・楽器演奏・音楽コンテンツなどの解析に広く応用が可能である。

---

## 3. 背景技術

### 3.1 マルチピッチ推定およびノート検出
従来のマルチピッチ推定技術には、フレームごとにスペクトルピークを解析する手法が存在する。しかし、複数音が同時に鳴る場合、単純なピーク識別では追跡が不安定になる。また、オンセット検出ではエネルギー包絡（エンベロープ）の急激な変化を利用することが多いが、アタックが緩やかな楽器音やノイズの混在下では誤検出が発生しやすい。

### 3.2 部分音追跡の必要性
楽音は多くの場合、基本周波数とその倍音（部分音）によって構成される。フレーム間で部分音を連続的に追跡することで、変化点や始まり（オンセット）、終わり（オフセット）をより安定的に推定できる。しかし、従来法ではフレーム間マッチングを貪欲法などで行うことが多く、ポリフォニー下やピークが密集する状況では最適な追跡が難しい場合がある。

---

## 4. 発明の概要

本発明は、**不予測度（Unpredictability）**を用いてマルチピッチとノート区間を高精度に検出するアルゴリズムである。  
以下のステップを包含している。

1. **短時間フーリエ変換（STFT）**による時周波解析  
2. 位相スペクトルを用いた**SPOD**（Stochastic Phase-Oriented Deviation）の算出  
3. スペクトルピーク検出による**部分音の抽出**  
4. **ハンガリアン法（Hungarian Algorithm）**を用いたフレーム間の部分音追跡  
5. 予測誤差に基づく**不予測度（Unpredictability）の算出**  
6. 不予測度の時間変化に基づく**オンセット検出**  
7. 検出結果を統合した**ノートセグメンテーション**

本アルゴリズムでは、位相進行や振幅変化を考慮した部分音レベルの誤差を統合し、不予測度を指標としてノートオンセットを高精度に捉える。また、単一パラメータ\(\beta\)により全体の検出感度やスムージング量などを制御でき、さまざまな音源・演奏スタイルに適応可能である。

---

## 5. 発明の特徴

1. **不予測度を利用したオンセット検出**  
   フレーム間で部分音の振幅・位相進行を予測し、その逸脱量を集約することで、穏やかなアタックやノイズが重畳する環境下でも安定してオンセットを捉える。

2. **SPOD（Stochastic Phase-Oriented Deviation）の導入**  
   位相のフレーム間差分の分散を指数関数的にマッピングすることで、各周波数成分の安定度を推定。部分音追跡のコスト関数に反映することで、ノイズ成分の誤追跡を抑制する。

3. **ハンガリアン法による部分音マッチング**  
   フレーム単位で検出されたピーク集合を、周波数差（セント換算）やSPOD差などをコストとした最適割り当てにより連続的に追跡する。局所的貪欲法に比べ、複数部分音が近接した場合でも精度が高い。

4. **単一パラメータ\(\beta\)による包括的制御**  
   不予測度のしきい値、スムージング時間、部分音マッチングの許容範囲などを\(\beta\)によって同時に調整可能。直感的かつ統合的な感度調整を実現する。

---

## 6. アルゴリズム構成

### 6.1 全体フローチャート

```
┌─────────────────────────────────┐
│ 1. 入力: 音声データ, サンプリング周波数 sr            │
└─────────────────────────────────┘
            │
            ▼
┌─────────────────────────────────┐
│ 2. STFT 計算:  振幅スペクトル S_amp, 位相 phases 等   │
└─────────────────────────────────┘
            │
            ▼
┌─────────────────────────────────┐
│ 3. SPOD 計算: 位相差分の分散から 0〜1 の安定度マップ   │
└─────────────────────────────────┘
            │
            ▼
┌─────────────────────────────────┐
│ 4. ピーク検出: 各フレームで主要スペクトルピークを抽出  │
└─────────────────────────────────┘
            │
            ▼
┌─────────────────────────────────┐
│ 5. 部分音追跡: ハンガリアン法でフレーム間マッチング    │
└─────────────────────────────────┘
            │
            ▼
┌─────────────────────────────────┐
│ 6. 不予測度算出: 部分音の予測誤差を統合                │
└─────────────────────────────────┘
            │
            ▼
┌─────────────────────────────────┐
│ 7. オンセット検出: 不予測度のピークを検出               │
└─────────────────────────────────┘
            │
            ▼
┌─────────────────────────────────┐
│ 8. ノートセグメンテーション: オンセットを基に音区間化    │
└─────────────────────────────────┘
            │
            ▼
┌─────────────────────────────────┐
│ 9. 出力: ノート区間, ピッチ, および部分音情報等         │
└─────────────────────────────────┘
```

---

## 7. 各工程の詳細

### 7.1 STFT計算（Step 2）
- 音声データに対して、設定された窓長 \(\text{N\_FFT}=2048\)、ホップ長 \(\text{HOP\_LENGTH}=1024\) を用いて短時間フーリエ変換を行う。窓関数にはHann窓などを使用する。  
- 得られた複素スペクトルから**振幅スペクトル**および**位相スペクトル**を抽出し、さらにログスケール（dB）へ変換したスペクトルも計算する。  
- フレームごとの時間情報 `_times`、および周波数ビンごとの中心周波数 `_freqs` を取得する。

### 7.2 SPOD計算（Step 3）
- フレーム間の位相スペクトルの差分を計算し、その分散を移動平均やガウシアンフィルタで平滑化する。  
- 分散が大きい箇所ほど位相がランダムに変化している可能性が高いとみなし、  
  \[
     \text{SPOD}(f, t) = \exp\bigl(-\alpha \cdot \text{Var}(\Delta\phi_{f,t})\bigr)
  \]
  のように定義する（\(\alpha\) は定数パラメータ）。  
- SPOD 値が高い周波数ビンは位相が安定しており、部分音成分の追跡において信頼度が高い。

### 7.3 ピーク検出（Step 4）
- 各フレームの振幅スペクトル \(\text{S\_amp}\) もしくは dB スペクトル \(\text{S\_db}\) を用いて、ピーク検出を行う。  
- ピーク高さの閾値（\(\text{ENERGY\_DB\_THRESHOLD}\)）やピーク間の最小距離（\(\text{PEAK\_DISTANCE\_BIN}\)）を設定して、ノイズピークを抑制する。  
- ピークが検出された場合、隣接ビンとのパラボリック補間を行い、周波数解像度を向上させる。  
- これにより、フレームごとに取得した「ピークの周波数・振幅・位相近似値」のリストを得る。

### 7.4 部分音追跡（Step 5）
- フレーム \(t\) と \(t+1\) で検出されたピークを**部分音**としてマッチングする。  
- マッチングには**ハンガリアン法**を使用し、次のようなコスト関数 \(\text{Cost}\) を設定する。
  \[
    \text{Cost}(p_1, p_2) = 
      \begin{cases}
        \Delta(\text{freq}) + w_\mathrm{spod}\cdot \Delta(\text{SPOD}) & (\Delta(\text{freq}) < \text{threshold}) \\
        \text{COST\_INF} & (\text{otherwise})
      \end{cases}
  \]
  - \(\Delta(\text{freq})\) はセント単位の周波数差  
  - \(\Delta(\text{SPOD})\) は SPOD 値の差（必要に応じて振幅差や位相差も考慮）  
  - \(\text{COST\_INF}\) はマッチング不可能を表す大きな定数  
- 割り当てられた部分音には `last_freq`, `history`（各フレームの周波数や振幅、位相を保存）などの属性を保持し、対応するピークが見つからなかった場合に一定フレーム数経過すると追跡を終了する。

### 7.5 不予測度の算出（Step 6）
- 部分音 \(p\) がフレーム \(t\) に存在するとき、その周波数・位相・振幅を \(t-1\) の情報から予測し、実際の観測値との差分を誤差として求める。  
- たとえば、
  \[
    E_{\mathrm{phase},p}(t) = 
      \bigl|\Delta\phi_p(t) - \Delta\phi_{p,\text{pred}}(t)\bigr|
  \]
  \[
    E_{\mathrm{freq},p}(t) = 
      \bigl|\text{freq}_p(t) - \text{freq}_{p,\text{pred}}(t)\bigr|
  \]
  などを定義し、さらに SPOD 値を重みとして加算する。  
- フレーム \(t\) の不予測度 \(U(t)\) は、同フレーム内の全部分音についてこれら誤差を集計したもの（総和や最大値など）とする。

### 7.6 オンセット検出（Step 7）
- フレーム列 \(\{U(t)\}\) を移動平均やガウシアンフィルタで平滑化し、正規化する。
- \(\beta\) によって決定される相対閾値 `relative_onset_threshold` を用い、  
  \[
    \text{find\_peaks}\Bigl(U_\text{smooth}(t)\Bigr)
  \]
  を行い、ピークフレームをオンセット（ノート開始）として識別する。  
- これにより、緩やかな立ち上がりを持つ音やノイズを含む場合でも、部分音の予測誤差増大としてオンセットを検出できる。

### 7.7 ノートセグメンテーション（Step 8）
- オンセットフレームの位置情報を用いて、部分音群を区切る形でノートの始まりと終わりを決定する。  
- ノートのピッチは、開始フレーム付近の主要部分音の基本周波数あるいは平均周波数を代表値として推定する。  
- さらに必要に応じて短すぎるノートの除去や、近接ノートのマージなどのポストプロセスを行う。

---

## 8. パラメータ \(\beta\) とその役割

- \(\beta\) は \([0, 1]\) の範囲をとり、不予測度計算、オンセット閾値設定、部分音マッチングなど複数のプロセスで参照される。
- 具体例として、
  - **スムージング長**: \(\beta = 0\) の場合は長め（頑健だが変化にやや鈍感）、\(\beta = 1\) の場合は短め（鋭敏だが誤検出リスク増）。
  - **相対閾値**: \(\beta\) が大きいほど閾値を低く設定し、微細なピークでもオンセットとみなす。
  - **部分音マッチングコスト**: \(\beta\) が大きいほど許容範囲を狭くし、高精度なマッチングを行う反面、新規部分音を生成しやすい。

---

## 9. 実施例（Pythonコード概要）

以下は本アルゴリズムの実施例を示す参考実装である。ライブラリとして NumPy、SciPy、Librosa などを用い、主要なステップを再現する。

```python
import numpy as np
import librosa
from scipy.ndimage import gaussian_filter1d, uniform_filter1d
from scipy.signal import find_peaks
from scipy.optimize import linear_sum_assignment

class UnpredictabilityBasedDetector:
    # 主要パラメータ
    N_FFT = 2048
    HOP_LENGTH = 1024
    MIN_FREQ_HZ = 30.0
    MAX_FREQ_HZ = 5000.0
    ENERGY_DB_THRESHOLD = -50.0
    PEAK_DISTANCE_BIN = 4
    PARTIAL_MAX_INACTIVE_FRAMES = 3
    PARTIAL_MATCH_MAX_COST = 50.0

    def __init__(self, beta=0.5):
        self.beta = beta
        self._calculate_internal_params()
        # 内部状態変数などの初期化

    def _calculate_internal_params(self):
        # βに応じてスムージング量やオンセット閾値を設定
        pass

    def detect(self, audio_data, sr):
        # 1. STFT計算
        S_complex = librosa.stft(audio_data, n_fft=self.N_FFT, hop_length=self.HOP_LENGTH)
        S_amp = np.abs(S_complex)
        phases = np.angle(S_complex)

        # 2. SPOD計算
        spod_map = self._calculate_spod(phases)

        # 3. ピーク検出
        peaks_per_frame = self._detect_peaks(S_amp)

        # 4. 部分音追跡
        partial_states = self._track_partials(peaks_per_frame, spod_map)

        # 5. 不予測度算出
        unpredictability = self._calculate_unpredictability(partial_states)

        # 6. オンセット検出
        onsets = self._detect_onsets_from_unpredictability(unpredictability)

        # 7. ノートセグメンテーション
        notes = self._segment_notes(partial_states, onsets)

        return notes

    # 以下、内部メソッドを省略または簡略化（_calculate_spod, _detect_peaks, _track_partials, etc.）
    ...
```

上記は概念実証レベルの実装例であり、特定のライブラリや関数呼び出しは一例である。実際の商用化または大規模システムへの適用においては、最適化、スレッド・リアルタイム制御、追加パラメータの調整などが必要となる場合がある。

---

## 10. 効果と利点

1. **精度の向上**  
   従来のエネルギー中心のオンセット検出に比べ、位相進行と振幅変化から算出される不予測度を用いることで、緩やかなアタックやノイズ混入下でも正確にオンセットを捉えられる。

2. **部分音連続性を活かした堅牢性**  
   ハンガリアン法によるフレーム間マッチングを通じ、倍音構造が複雑でも、複数音が同時発生する状況でも頑健に追跡が可能。

3. **パラメータ\(\beta\)による操作性**  
   分散したパラメータ設定を\(\beta\)に集約しており、実用時のチューニングを簡単化。幅広い音楽ジャンルや楽器に対応できる。

4. **ポリフォニック音源への対応**  
   部分音を個別に追跡するため、和音や複数楽器が同時に発音するポリフォニー環境でも高い再現性を持つ。

---

## 11. 応用例

- **自動採譜**: WAVなどの音源ファイルからMIDI情報を生成し、楽譜を作成するシステム。  
- **音楽学習ツール**: 演奏の正確性（音程、タイミング）フィードバック。  
- **大規模音楽解析**: 音楽ライブラリから特定フレーズを検索、音楽理論的解析への応用。  
- **リアルタイム合奏支援**: リアルタイムでのマルチピッチ検出により、アンサンブルの調和やリズム解析などを行う。

---

## 12. 特許請求の範囲（サンプル）

**請求項1**  
音声信号を短時間フーリエ変換により時間フレームごとの複数の周波数ビンに変換し、各周波数ビンの位相スペクトルを算出する工程と、  
前記位相スペクトルのフレーム間変化に基づき、ランダム性の度合いを示す指標としてのSPODを求める工程と、  
前記時間フレームごとにスペクトルピークを検出し、フレーム間で最適割り当てを行うことで部分音として追跡する工程と、  
前記部分音に対する周波数・位相・振幅等の予測誤差を集計し、不予測度を算出する工程と、  
当該不予測度の時間変化に基づいてオンセットを検出し、ノート区間を決定する工程と、  
を含むことを特徴とするマルチピッチ・ノート検出方法。

**請求項2**  
請求項1に記載の方法において、不予測度を算出する工程で位相進行予測誤差と振幅変化予測誤差を統合し、更にSPOD値を重み付けとして用いることを特徴とするマルチピッチ・ノート検出方法。

**請求項3**  
請求項1または2に記載の方法において、単一パラメータ\(\beta\)を用いてオンセット検出感度、スムージング量、および部分音マッチング閾値を制御することを特徴とするマルチピッチ・ノート検出方法。

> ※実際の特許明細書では、請求項の形式・文言・階層構造などを専門家と共に厳密に検討する必要があります。

---

## 13. まとめ

本仕様書では、不予測度（Unpredictability）を用いたマルチピッチ・ノート検出アルゴリズムを示した。  
- **SPOD** を活用して位相のランダム性を捉える手法と、  
- **ハンガリアン法**を用いた部分音追跡により、  
複数音が重なるポリフォニックな楽音信号に対しても頑健なマルチピッチ・ノート検出が可能となる。  
さらに、単一パラメータ \(\beta\) によって、検出感度や各種閾値を包括的に制御できる特長を持ち、多様な音源環境や音楽ジャンルに適応しやすい。

本発明は、自動採譜システムやリアルタイム演奏解析、多様な音楽情報検索システムなどに対して広範な応用が見込まれ、音響解析の精度向上と処理効率化に寄与する。